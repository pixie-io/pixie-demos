import px

nanos_per_hour = 60*60*1000*1000*1000
cpu_cost_per_hour = 0.05


def cpu_time_ns_by_service():
    # Load the last 1 hr of Pixie's `process_stats` table into a Dataframe.
    # The `process_stats` table contains CPU, memory and IO stats for all
    # K8s processes in your cluster.
    df = px.DataFrame(table='process_stats', start_time="-1h")

    # Add K8s context using the table record's UPID.
    df.service = df.ctx['service']

    # Group data by unique pairs of the 'service' 'upid' columns and calculate
    # the sum of the 'cpu_utime_ns' and 'cpu_ktime_ns' for each unique grouping.
    df = df.groupby(['service', 'upid']).agg(
        # The fields below are counters, so we take the min (starting value)
        # and the max (ending value) to subtract them.
        cpu_utime_ns_max=('cpu_utime_ns', px.max),
        cpu_utime_ns_min=('cpu_utime_ns', px.min),
        cpu_ktime_ns_max=('cpu_ktime_ns', px.max),
        cpu_ktime_ns_min=('cpu_ktime_ns', px.min)
    )

    df.cpu_utime_ns = df.cpu_utime_ns_max - df.cpu_utime_ns_min
    df.cpu_ktime_ns = df.cpu_ktime_ns_max - df.cpu_ktime_ns_min

    # Group by unique service and calculate the sum of CPU time.
    df = df.groupby('service').agg(
        cpu_utime_ns=('cpu_utime_ns', px.sum),
        cpu_ktime_ns=('cpu_ktime_ns', px.sum)
    )

    df.cpu_time_ns = px.DurationNanos(df.cpu_ktime_ns + df.cpu_utime_ns)

    return df


def yearly_cpu_cost_by_service():
    df = cpu_time_ns_by_service()
    df.cpu_time_frac_hour = df.cpu_time_ns / nanos_per_hour
    df.cpu_cost_per_year = df.cpu_time_frac_hour * cpu_cost_per_hour * 24 * 365
    return df[['service', 'cpu_cost_per_year']]


def yearly_cpu_cost():
    df = yearly_cpu_cost_by_service()
    return df.agg(
       cpu_cost_per_year=('cpu_cost_per_year', px.sum)
    )


df = yearly_cpu_cost_by_service()
px.display(df, 'CPU Cost By Service (Yearly)')

df = yearly_cpu_cost()
px.display(df, 'CPU Cost (Yearly)')
