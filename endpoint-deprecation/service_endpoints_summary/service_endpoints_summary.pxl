# Copyright 2018- The Pixie Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

''' Service Endpoints Summary

 This script gets an overview of the endpoints for a service, summarizing their request statistics.
'''
import px


# Flag to filter out requests that come from an unresolvable IP.
filter_unresolved_inbound = True
# Flag to filter out health checks from the data.
filter_health_checks = True
# Flag to filter out ready checks from the data.
filter_ready_checks = True


def get_time_window(start_time: str):
    ''' Converts the start_time string into a table with a single column and single row.
    The approach is hacky, and will round to roughly 1 second.
    '''
    df = px.DataFrame('process_stats', start_time=start_time)

    df = df.agg(
        time_min=('time_', px.min),
        time_max=('time_', px.max),
    )

    df.window = px.DurationNanos(df.time_max - df.time_min)
    df = df[['window']]

    return df


def add_time_window_column(df, start_time):
    tw = get_time_window(start_time)
    df = df.merge(tw, how='inner', left_on=[], right_on=[])
    return df


def endpoints(start_time: str, service: px.Service):
    ''' Get a list of the endpoints in `service` along with LET statistics.

    Args:
    @start_time: The timestamp of data to start at.
    @service: The service to filter on.

    '''
    df = endpoint_let_helper(start_time, service)
    df = request_path_endpoint_clustering(df)

    # Compute HTTP LET metrics.
    df = df.groupby(['endpoint']).agg(
        throughput_total=('latency', px.count),
        error_count=('failure', px.sum),
        latency_quantiles=('latency', px.quantiles)
    )

    # Compute time window for the query and add it as a column.
    df = add_time_window_column(df, start_time)

    # Compute throughput values.
    df.throughput = df.throughput_total / df.window
    df.error_rate = px.Percent(
        px.select(df.throughput_total != 0, df.error_count / df.throughput_total, 0.0))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))

    df.endpoint = px.script_reference(df.endpoint, 'pxbeta/service_endpoint', {
        'start_time': start_time,
        'service': service,
        'endpoint': df.endpoint,
    })

    return df[['endpoint', 'latency_p90', 'error_rate', 'throughput', 'throughput_total']]


def endpoint_let_helper(start_time: str, service: px.Service):
    ''' Compute the let as a timeseries for requests received or by services in `namespace`.

    Args:
    @start_time: The timestamp of data to start at.
    @namespace: The namespace to filter on.
    @groupby_cols: The columns to group on.

    '''
    df = px.DataFrame(table='http_events', start_time=start_time)

    # Filter only to inbound service traffic (server-side).
    # Don't include traffic initiated by this service to an external location.
    df = df[df.trace_role == 2]

    df.service = df.ctx['service']
    df = df[px.contains(df.service, service)]
    df.failure = df.resp_status >= 400

    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (
        df.req_path != '/readyz' or not filter_ready_checks)) and (
        df['remote_addr'] != '-' or not filter_unresolved_inbound)
    df = df[filter_out_conds]

    return df


def request_path_endpoint_clustering(let_df):
    clustering_df = let_df.agg(
        clustering=("req_path", px._build_request_path_clusters)
    )
    merged_df = let_df.merge(
        clustering_df, how="outer", right_on=[], left_on=[], suffixes=["", ""]
    )
    merged_df.endpoint = px._predict_request_path_cluster(
        merged_df.req_path, merged_df.clustering
    )
    merged_df.drop(["clustering"])
    return merged_df
